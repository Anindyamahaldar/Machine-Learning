{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ASSIGNMENT"
      ],
      "metadata": {
        "id": "i71h1vvyPQgH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "kZ5_7M1KPTad"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment Questions"
      ],
      "metadata": {
        "id": "DLt3usjMPY-F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a parameter?\n",
        "- A parameter in machine learning is a variable that a model learns from data to improve its predictions. Parameters are internal to the model and are used to represent the relationships in the data.\n",
        "\n",
        "2. What is correlation? What does negative correlation mean?\n",
        "- In machine learning, \"correlation\" refers to a statistical measure that indicates the strength and direction of the relationship between two variables, essentially showing how closely two variables change together, allowing you to understand if one variable increases or decreases as the other does, helping in data analysis and feature selection for building models.\n",
        "   - In machine learning, a \"negative correlation\" means that when one variable increases, the other variable tends to decrease, indicating that the two variables move in opposite directions; essentially, as one value goes up, the other goes down, and vice versa - also known as an inverse correlation.\n",
        "\n",
        "3. Define Machine Learning. What are the main components in Machine Learning?\n",
        "- Machine learning is a subset of AI, which uses algorithms that learn from data to make predictions. These predictions can be generated through supervised learning, where algorithms learn patterns from existing data, or unsupervised learning, where they discover general patterns in data.\n",
        "\n",
        "4. How does loss value help in determining whether the model is good or not?\n",
        "- A lower loss value indicates a better performing model, as it signifies that the model's predictions are closer to the actual values, meaning it makes fewer errors; essentially, a smaller \"loss\" between predicted and true outputs signifies a better model overall.\n",
        "\n",
        "5. What are continuous and categorical variables?\n",
        "- In machine learning, a continuous variable is a numerical variable that can take on any value within a given range, meaning there are infinitely possible values between any two points on the scale (like height, weight, or temperature), while a categorical variable is a variable that represents distinct categories or groups, where the data can only fall into one of a limited set of predefined categories (like gender, hair color, or country of origin).\n",
        "\n",
        "6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "- To handle categorical variables in machine learning, the most common technique is to convert them into numerical representations using encoding methods like one-hot encoding, label encoding, ordinal encoding, target encoding, frequency encoding, and binary encoding; the choice depends on whether the categorical variable has an inherent order (ordinal) or not (nominal), and the desired level of dimensionality reduction.\n",
        "\n",
        "7. What do you mean by training and testing a dataset?\n",
        "- In machine learning, datasets are typically split into two subsets: training and testing data. The training data is used to train the machine learning algorithm. The testing data is used to evaluate the accuracy of the trained algorithm.\n",
        "\n",
        "8. What is sklearn.preprocessing?\n",
        "- Sklearn.preprocessing is a Python package that contains tools for changing raw data into a format that's better suited for machine learning models. These tools include scalers, transformers, and normalizers.\n",
        "\n",
        "9. What is a Test set?\n",
        "- A test set is a group of tests or a portion of data that is used to evaluate the performance of a model or system.\n",
        "\n",
        "10. How do we split data for model fitting (training and testing) in Python?\n",
        "- To split data for model fitting (training and testing) in Python, you primarily use the train_test_split function from the scikit-learn library, which allows you to randomly divide your dataset into a training set (used to train the model) and a testing set (used to evaluate the model's performance on unseen data) by specifying the desired test size as a percentage of the total data; you can also set a random state to ensure reproducibility of the split.\n",
        "  - To approach a Machine Learning problem, you should first clearly define the problem and desired outcome, then gather and prepare your data, choose an appropriate model based on the data type and problem complexity, train the model, evaluate its performance using relevant metrics, and finally, deploy the model for predictions while monitoring its effectiveness in real-world scenarios; throughout the process, consider factors like data quality, feature engineering, and domain expertise to optimize your results.\n",
        "\n",
        "11. Why do we have to perform EDA before fitting a model to the data?\n",
        "- Performing Exploratory Data Analysis (EDA) before fitting a model to data is crucial because it allows you to gain a deep understanding of your data's structure, identify potential issues like outliers, missing values, or incorrect data types, and ultimately inform the best way to preprocess and feature engineer your data before building a model, leading to a more accurate and reliable prediction outcome; essentially, it helps you make informed decisions about your model building process by understanding the underlying patterns and characteristics of your data first.\n",
        "\n",
        "12. In machine learning, \"correlation\" refers to a statistical measure that describes the strength and direction of the relationship between two variables, indicating how closely they tend to change together, with a value ranging from -1 (perfect negative correlation) to +1 (perfect positive correlation), where 0 signifies no correlation at all; it's a key tool for exploring data, selecting features, and evaluating models by understanding how different variables are related to each other.\n",
        "\n",
        "13. What does negative correlation mean?\n",
        "- In machine learning, a \"negative correlation\" means that when one variable increases, the other variable tends to decrease, indicating that the two variables move in opposite directions; essentially, as one goes up, the other goes down, and vice versa - also known as an inverse correlation.\n",
        "\n",
        "14. How can you find correlation between variables in Python?\n",
        "- To calculate correlation in Python, you can use the pandas library, specifically the corr() method for DataFrames. It returns a correlation matrix showing the relationships between variables.\n",
        "\n",
        "15. What is causation? Explain difference between correlation and causation with an example.\n",
        "- In machine learning, \"causation\" refers to the process of identifying and understanding the cause-and-effect relationships between variables in a dataset, meaning it goes beyond simply observing correlations to determine which variable actively influences another, allowing for more insightful predictions and informed decision-making based on the underlying mechanisms at play; essentially, it's about figuring out \"why\" something happens, not just \"that\" it happens.\n",
        "   - While \"correlation\" simply means two variables tend to change together, \"causation\" means one variable directly influences or causes a change in another; essentially, correlation does not imply causation.\n",
        "Example: Ice cream sales and the number of shark attacks often increase during the summer months, meaning they are correlated, but this doesn't mean eating ice cream causes shark attacks; the real cause is likely the warmer weather which leads to more people swimming in the ocean and more ice cream consumption.\n",
        "\n",
        "16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "- An optimizer is an algorithm that adjusts the weights and biases of a machine learning model to minimize loss and improve performance. Optimizers are a crucial part of the training process for neural networks.\n",
        "        - Types of Optimizers\n",
        "\n",
        "           Here are some of the most commonly used optimizers:\n",
        "\n",
        "           Gradient Descent (GD)\n",
        "            Concept: The most basic optimizer. It works by calculating the gradient of the loss function (which indicates the direction of the steepest ascent) and then moving in the opposite direction (steepest descent) to find the minimum.\n",
        "               Example: Imagine you're at the top of a mountain and want to find the lowest point. Gradient descent is like taking small steps downhill, always in the direction that seems steepest.\n",
        "            Limitations: Can be slow and get stuck in local minima (valleys in the mountain that aren't the absolute lowest point).\n",
        "          Stochastic Gradient Descent (SGD)\n",
        "            Concept: An improvement over GD. Instead of calculating the gradient over the entire dataset, it calculates it for a single data point or a small batch of data points at a time.\n",
        "               Example: Instead of looking at the whole mountain at once, you take a step downhill based on the slope at your current location.\n",
        "          Advantages: Faster than GD and can help escape local minima.\n",
        "           Limitations: Can be noisy and unstable due to the randomness in selecting data points.\n",
        "             Adam (Adaptive Moment Estimation)\n",
        "          Concept: A popular optimizer that combines ideas from other optimizers (like momentum and RMSprop). It adapts the learning rate for each parameter, making it very efficient.\n",
        "            Example: It's like having a smart guide who not only knows the steepest way down the mountain but also adjusts your steps based on the terrain and your progress.\n",
        "                Advantages: Generally performs well on a variety of problems and requires less tuning of hyperparameters.\n",
        "           RMSprop (Root Mean Square Propagation)\n",
        "          Concept: Another adaptive optimizer that adjusts the learning rate based on the average of recent gradients.\n",
        "                 Example: Similar to Adam, it helps navigate the mountain efficiently by considering the recent steepness of the slopes.\n",
        "                    Advantages: Often a good choice for problems with noisy or non-stationary data.\n",
        "           Adagrad (Adaptive Gradient Algorithm)\n",
        "           Concept: Adapts the learning rate for each parameter based on the historical gradients. Parameters that have received large gradients in the past get smaller learning rates.\n",
        "                Example: It's like being more cautious on slopes you've found to be slippery in the past.\n",
        "                   Limitations: Can sometimes decrease the learning rate too aggressively, leading to slow convergence.\n",
        "                Choosing the Right Optimizer\n",
        "\n",
        "\n",
        "17. What is sklearn.linear_model ?\n",
        "- linear_model is a class of the sklearn module if contain different functions for performing machine learning with linear models. The term linear model implies that the model is specified as a linear combination of features.\n",
        "\n",
        "18. What does model.fit() do? What arguments must be given?\n",
        "- The fit() method in Scikit-learn is the core function used to train machine learning models. It takes the training data and the corresponding labels (for supervised learning tasks) and learns the parameters or patterns from this data.\n",
        "  - model. fit() : fit training data. For supervised learning applications, this accepts two arguments: the data X and the labels y (e.g. model. fit(X, y) ).\n",
        "\n",
        "19. What does model.predict() do? What arguments must be given?\n",
        "- Model. predict passes the input vector through the model and returns the output tensor for each datapoint. Since the last layer in your model is a single Dense neuron, the output for any datapoint is a single value. And since you didn't specify an activation for the last layer, it will default to linear activation.\n",
        "\n",
        "20. What are continuous and categorical variables?\n",
        "- A continuous variable is a variable that can take on any value within a given range, meaning there are infinitely possible values between any two points on the scale, like height, weight, or temperature; while a categorical variable is a variable that can only take on a limited number of distinct categories, like gender (male/female), hair color (brown, blonde, black), or blood type (A, B, AB, O).\n",
        "\n",
        "21. What is feature scaling? How does it help in Machine Learning?\n",
        "- Feature scaling is a data preprocessing technique in machine learning where numerical features in a dataset are transformed to have a similar scale, ensuring that no single feature dominates the model's learning process due to its significantly larger range of values; this helps improve the performance of many machine learning algorithms, especially those that rely on distance calculations like K-Nearest Neighbors or algorithms using gradient descent, by allowing them to converge faster and make more accurate predictions.\n",
        "\n",
        "22. How do we perform scaling in Python?\n",
        "- To perform scaling in Python, you typically use the StandardScaler class from the sklearn.preprocessing module to standardize your data (meaning it will have a mean of 0 and a standard deviation of 1), or the MinMaxScaler class to scale your data to a specific range, usually between 0 and 1, by applying the formula: (value - min) / (max - min); both methods are commonly used for feature scaling in machine learning tasks.\n",
        "\n",
        "23. What is sklearn.preprocessing?\n",
        "- The sklearn.preprocessing package provides several common utility functions and transformer classes to change raw feature vectors into a representation that is more suitable for the downstream estimators.\n",
        "\n",
        "24. How do we split data for model fitting (training and testing) in Python?\n",
        "- To split data for model fitting (training and testing) in Python, you primarily use the train_test_split function from the scikit-learn library, which allows you to randomly divide your dataset into a training set (used to train the model) and a testing set (used to evaluate the model's performance on unseen data) by specifying the desired test size as a percentage of the total data; you can also set a random state to ensure reproducibility of the split.\n",
        "\n",
        "25. Explain data encoding?\n",
        "- Data encoding is the process of converting data into a specific format for storage, transmission, or analysis. It's a fundamental technique in data science and computing.\n"
      ],
      "metadata": {
        "id": "9wGXp-ZNPfgV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7HzsQb5PK7d"
      },
      "outputs": [],
      "source": []
    }
  ]
}